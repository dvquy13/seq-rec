{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "\n",
                "from google.cloud import storage\n",
                "import google.cloud.aiplatform as aip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROJECT_ID = \"seq-rec-gcp-project-id\"\n",
                "MODEL_NAME = 'seq-rec-model-v0'\n",
                "SAVED_MODEL_PATH = f'models/{MODEL_NAME}'\n",
                "\n",
                "BUCKET_LOCATION = \"ASIA-SOUTHEAST1\"\n",
                "BUCKET_NAME = \"recsys-pipeline\"\n",
                "BUCKET_FOLDER_DIR = F\"seq-rec/{MODEL_NAME}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def upload_local_directory_to_gcs(local_path, bucket_name, gcs_path):\n",
                "    gcs_client = storage.Client()\n",
                "\n",
                "    bucket = gcs_client.get_bucket(bucket_name)\n",
                "    assert os.path.isdir(local_path)\n",
                "    for local_file in glob.glob(local_path + '/**'):\n",
                "        if not os.path.isfile(local_file):\n",
                "            upload_local_directory_to_gcs(local_file, bucket, gcs_path + \"/\" + os.path.basename(local_file))\n",
                "        else:\n",
                "            remote_path = os.path.join(gcs_path, local_file[1 + len(local_path):])\n",
                "            blob = bucket.blob(remote_path)\n",
                "            blob.upload_from_filename(local_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "upload_local_directory_to_gcs(SAVED_MODEL_PATH, BUCKET_NAME , BUCKET_FOLDER_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create endpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ref: https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_create_endpoint_sample-gcloud"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ENDPOINT_VARS = dict(\n",
                "    ENDPOINT_LOCATION=\"asia-southeast1\",\n",
                "    ENDPOINT_NAME=\"seq-rec-model\",\n",
                "    ENDPOINT_VERSION=\"v0\",\n",
                "    MODEL_NAME=MODEL_NAME,\n",
                "    PATH_TO_MODEL_ARTIFACT_DIRECTORY=f\"gs://{BUCKET_NAME}/{BUCKET_FOLDER_DIR}\",\n",
                "    CONTAINER_IMAGE_URI=\"asia-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\",\n",
                "    # CONTAINER_IMAGE_URI=\"asia.gcr.io/seq-rec-gcp-project-id/tf-serving-scann\",\n",
                "    ENDPOINT_MACHINE_TYPE=\"n1-standard-2\",\n",
                "    ENDPOINT_MIN_REPLICA_COUNT=\"1\",\n",
                "    ENDPOINT_MAX_REPLICA_COUNT=\"1\",\n",
                "    BUCKET_LOCATION=BUCKET_LOCATION,\n",
                "    BUCKET_NAME=BUCKET_NAME,\n",
                "    BUCKET_FOLDER_DIR=BUCKET_FOLDER_DIR\n",
                ")\n",
                "\n",
                "for var_key, var_value in ENDPOINT_VARS.items():\n",
                "    os.environ[var_key] = var_value"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Upload model to Vertex AI Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "aip.init(project=PROJECT_ID, location=ENDPOINT_VARS['ENDPOINT_LOCATION'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ref: https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_custom_tabular_regression_online_explain.ipynb\n",
                "\n",
                "model = aip.Model.upload(\n",
                "    display_name=ENDPOINT_VARS['MODEL_NAME'],\n",
                "    artifact_uri=ENDPOINT_VARS['PATH_TO_MODEL_ARTIFACT_DIRECTORY'],\n",
                "    serving_container_image_uri=ENDPOINT_VARS['CONTAINER_IMAGE_URI'],\n",
                "    sync=False\n",
                ")\n",
                "\n",
                "model.wait()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Deploy the model to endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "TRAFFIC_SPLIT = {\"0\": 100}\n",
                "DEPLOY_GPU = False\n",
                "\n",
                "endpoint = model.deploy(\n",
                "    deployed_model_display_name=ENDPOINT_VARS['MODEL_NAME'],\n",
                "    traffic_split=TRAFFIC_SPLIT,\n",
                "    machine_type=ENDPOINT_VARS['ENDPOINT_MACHINE_TYPE'],\n",
                "    accelerator_type=DEPLOY_GPU,\n",
                "    accelerator_count=0,\n",
                "    min_replica_count=int(ENDPOINT_VARS['ENDPOINT_MIN_REPLICA_COUNT']),\n",
                "    max_replica_count=int(ENDPOINT_VARS['ENDPOINT_MAX_REPLICA_COUNT']),\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test the deployed model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "instances = [\n",
                "    {\n",
                "        \"context_merchants\": [\"<EXAMPLE_MERCHANT_ID>\"],\n",
                "        \"context_search_terms\": [\"<EXAMPLE_SEARCH_TERM>\"],\n",
                "        \"context_merchants_time_recency\": [\"1\"],\n",
                "        \"context_search_terms_time_recency\": [\"1\"]\n",
                "    }\n",
                "]\n",
                "prediction = endpoint.predict(instances=instances)\n",
                "prediction"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.14 ('.venv': poetry)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.14"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "eaeefced7af4788b9b4a203895b09193a6dd449d207d1b1237ec1e0a47ffeed0"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
